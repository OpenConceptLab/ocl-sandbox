{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-Encoder and Cross-Encoder Model Evaluation for Medical Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Evaluation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def evaluate_model(model_name: str, model_type: str, df_evaluation: DataFrame)-> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model by calculating the similarity between source and target terms/sentences; \n",
    "    then, calculate the percentage of matches using the highest similarity score.\n",
    "    \n",
    "    Args:\n",
    "        model_name: The SentenceTransformer model to use for encoding.\n",
    "        model_type: BiEncoder or CrossEncoder.\n",
    "        df_evaluation: DataFrame containing 'source' and 'target' columns.\n",
    "    \n",
    "    Returns:\n",
    "        percentage_of_matches: Percentage of matches with the highest similarity score.\n",
    "    \"\"\" \n",
    "    if model_type == \"BiEncoder\":     \n",
    "        model = SentenceTransformer(model_name)       \n",
    "        # Calculate embeddings for source and target sentences\n",
    "        source_embeddings = model.encode(df_evaluation['source'].tolist())\n",
    "        target_embeddings = model.encode(df_evaluation['target'].tolist())\n",
    "\n",
    "        # Calculate similarities\n",
    "        similarities = model.similarity(source_embeddings, target_embeddings)\n",
    "    elif model_type == \"CrossEncoder\":\n",
    "        model = CrossEncoder(model_name)\n",
    "        \n",
    "        # Create all possible pairs between sources and targets\n",
    "        sources = df_evaluation['source'].tolist()\n",
    "        targets = df_evaluation['target'].tolist()\n",
    "        pairs = [(src, tgt) for src in sources for tgt in targets]\n",
    "\n",
    "        # Predict similarities for all pairs\n",
    "        similarity_scores = model.predict(pairs, convert_to_tensor=True)\n",
    "\n",
    "        # Reshape the flat similarity scores into a matrix (num_sources x num_targets)\n",
    "        similarities = similarity_scores.view(len(sources), len(targets))\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Invalid model_type. Choose either 'BiEncoder' or 'CrossEncoder'.\")\n",
    "\n",
    "    df_similarities = pd.DataFrame(similarities.numpy())\n",
    "\n",
    "    # Find the index of the highest score in each column\n",
    "    max_idx_col = df_similarities.values.argmax(axis=0)\n",
    "\n",
    "    # Calculate the percentage where the highest score is on the diagonal\n",
    "    number_of_matches = np.sum(max_idx_col == np.arange(df_similarities.shape[1]))\n",
    "    percentage_of_matches = (number_of_matches / df_similarities.shape[1]) * 100\n",
    "    \n",
    "    return percentage_of_matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the evaluation dataset\n",
    "df_raw = pd.read_csv('data\\\\bc-health-concerns-and-diagnosis-value-set-v3-constrained.csv')\n",
    "df_data = df_raw[['SNOMED_Term', 'ICD10CA_Term']].copy()\n",
    "df_data.columns = ['source', 'target']\n",
    "df_data = df_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Save Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: all-MiniLM-L6-v2, Type: BiEncoder, Accuracy: 90.00%\n",
      "Model: sentence-transformers/all-mpnet-base-v2, Type: BiEncoder, Accuracy: 90.00%\n",
      "Model: sentence-transformers/allenai-specter, Type: BiEncoder, Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "df_model= pd.read_csv('Models.csv')\n",
    "\n",
    "for idx, row in df_model.iterrows():\n",
    "    \n",
    "    model_name = row['Model'].strip()\n",
    "    model_type = row['Model Type'].strip()\n",
    "    accuracy = evaluate_model(model_name, model_type, df_data)\n",
    "    df_model.at[idx, 'Accuracy'] = accuracy\n",
    "    \n",
    "    print(f\"Model: {model_name}, Type: {model_type}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "df_model.to_csv('Models_Accuracy.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
